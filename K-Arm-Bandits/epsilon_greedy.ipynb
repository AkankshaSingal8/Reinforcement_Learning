{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KArmedBandit:\n",
    "    def __init__(self, k=10, epsilon=0.1):\n",
    "        self.k = k  # Number of arms\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        self.q_star = np.random.normal(0, 1, k)  # True action values (q*)\n",
    "        self.q_estimates = np.zeros(k)  # Estimated action values (Q(a))\n",
    "        self.action_counts = np.zeros(k)  # Number of times each action was taken\n",
    "\n",
    "    def select_action(self):\n",
    "        \"\"\"Select an action using epsilon-greedy strategy.\"\"\"\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Explore: Randomly choose one of the k actions\n",
    "            return np.random.randint(self.k)\n",
    "        else:\n",
    "            # Exploit: Choose the action with the highest estimated value\n",
    "            return np.argmax(self.q_estimates)\n",
    "\n",
    "    def get_reward(self, action):\n",
    "        \"\"\"Generate a reward for the selected action.\"\"\"\n",
    "        # Reward is drawn from a normal distribution centered at the true value of the action\n",
    "        return np.random.normal(self.q_star[action], 1)\n",
    "\n",
    "    def update_estimates(self, action, reward):\n",
    "        \"\"\"Update the estimated value of the selected action.\"\"\"\n",
    "        self.action_counts[action] += 1\n",
    "        # Incremental update of the estimated action value (Q(a))\n",
    "        self.q_estimates[action] += (reward - self.q_estimates[action]) / self.action_counts[action]\n",
    "\n",
    "    def run(self, steps=1000):\n",
    "        \"\"\"Run the epsilon-greedy algorithm for a specified number of steps.\"\"\"\n",
    "        rewards = np.zeros(steps)\n",
    "        average_rewards = np.zeros(steps)\n",
    "        total_reward = 0\n",
    "\n",
    "        for step in range(steps):\n",
    "            action = self.select_action()\n",
    "            reward = self.get_reward(action)\n",
    "            self.update_estimates(action, reward)\n",
    "            rewards[step] = reward\n",
    "            total_reward += reward\n",
    "            average_rewards[step] = total_reward / (step + 1)\n",
    "\n",
    "        return average_rewards\n",
    "\n",
    "# Parameters\n",
    "k = 10\n",
    "epsilon = 0.1\n",
    "steps = 1000\n",
    "\n",
    "# Initialize the k-armed bandit\n",
    "bandit = KArmedBandit(k=k, epsilon=epsilon)\n",
    "\n",
    "# Run the algorithm and collect average rewards\n",
    "average_rewards = bandit.run(steps=steps)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(average_rewards, label=f'Epsilon = {epsilon}')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Average Reward')\n",
    "plt.title('Epsilon-Greedy: Average Reward vs. Steps')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
